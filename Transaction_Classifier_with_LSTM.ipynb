{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyPbaM8xQsIvfMD6b2t5PJng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahanam05/deep-learning/blob/main/Transaction_Classifier_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "x0V0gHGp2T4S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from time import time\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from collections import Counter\n",
        "\n",
        "# configurations\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_SIZE = 100\n",
        "MAX_LENGTH = 7\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 7\n",
        "TEST_SPLIT_RATIO = 0.2\n",
        "\n",
        "# sample data (173 examples)\n",
        "DATA = [\n",
        "    (\"bought vegetables and rice from supermarket\", \"grocery\"),\n",
        "    (\"picked up fresh chicken from local butcher\", \"grocery\"),\n",
        "    (\"bought snacks and juice from convenience store\", \"grocery\"),\n",
        "    (\"morning coffee from café near office\", \"grocery\"),\n",
        "    (\"purchased fruits for the week\", \"grocery\"),\n",
        "    (\"bought bread and butter from bakery\", \"grocery\"),\n",
        "    (\"weekly grocery run at hypermarket\", \"grocery\"),\n",
        "    (\"ordered pizza for dinner\", \"grocery\"),\n",
        "    (\"purchased chocolates from duty free shop\", \"grocery\"),\n",
        "    (\"bought spices and lentils for cooking\", \"grocery\"),\n",
        "    (\"picked up cereal and milk\", \"grocery\"),\n",
        "    (\"bought onions, tomatoes, and coriander\", \"grocery\"),\n",
        "    (\"monthly stock-up of packaged food\", \"grocery\"),\n",
        "    (\"purchased cookies and tea bags\", \"grocery\"),\n",
        "    (\"grabbed a sandwich on the go\", \"grocery\"),\n",
        "    (\"picked up frozen food items\", \"grocery\"),\n",
        "    (\"purchased pasta and sauce bottles\", \"grocery\"),\n",
        "    (\"bought protein bars at store\", \"grocery\"),\n",
        "    (\"weekly fresh produce market visit\", \"grocery\"),\n",
        "    (\"picked up biscuits and wafers\", \"grocery\"),\n",
        "    (\"bought cheese slices and yoghurt\", \"grocery\"),\n",
        "    (\"purchased coffee beans\", \"grocery\"),\n",
        "    (\"bought cooking oil and sugar\", \"grocery\"),\n",
        "    (\"picked up chocolates for friends\", \"grocery\"),\n",
        "    (\"bought water bottles and soft drinks\", \"grocery\"),\n",
        "    (\"purchased instant noodles pack\", \"grocery\"),\n",
        "    (\"bought salad ingredients\", \"grocery\"),\n",
        "    (\"picked up green tea packets\", \"grocery\"),\n",
        "    (\"ordered sushi from restaurant\", \"grocery\"),\n",
        "    (\"bought ice cream for dessert\", \"grocery\"),\n",
        "    (\"purchased eggs and bread for breakfast\", \"grocery\"),\n",
        "    (\"picked up burger meal\", \"grocery\"),\n",
        "    (\"bought kitchen spices kit\", \"grocery\"),\n",
        "    (\"purchased bakery pastries\", \"grocery\"),\n",
        "    (\"picked up fresh herbs from store\", \"grocery\"),\n",
        "    (\"bought frozen vegetables\", \"grocery\"),\n",
        "    (\"ordered biryani for lunch\", \"grocery\"),\n",
        "    (\"purchased tea and sugar\", \"grocery\"),\n",
        "    (\"bought tortillas and salsa\", \"grocery\"),\n",
        "    (\"picked up canned beans\", \"grocery\"),\n",
        "    (\"bought peanut butter and jam\", \"grocery\"),\n",
        "    (\"purchased energy drinks\", \"grocery\"),\n",
        "    (\"grabbed donuts for office\", \"grocery\"),\n",
        "    (\"bought flour and yeast\", \"grocery\"),\n",
        "    (\"picked up packaged chips\", \"grocery\"),\n",
        "    (\"ordered burger and fries\", \"grocery\"),\n",
        "    (\"bought marshmallows for camping\", \"grocery\"),\n",
        "    (\"monthly grocery supply\", \"grocery\"),\n",
        "    (\"picked up avocados and bananas\", \"grocery\"),\n",
        "    (\"purchased soup packets\", \"grocery\"),\n",
        "    (\"uber ride to office\", \"travel\"),\n",
        "    (\"taxi to railway station\", \"travel\"),\n",
        "    (\"bus ticket to downtown\", \"travel\"),\n",
        "    (\"flight booking to Mumbai\", \"travel\"),\n",
        "    (\"train reservation for weekend trip\", \"travel\"),\n",
        "    (\"metro pass recharge\", \"travel\"),\n",
        "    (\"cab ride to friend’s house\", \"travel\"),\n",
        "    (\"airport shuttle service payment\", \"travel\"),\n",
        "    (\"fuel refill for car\", \"travel\"),\n",
        "    (\"toll booth payment\", \"travel\"),\n",
        "    (\"hotel stay during conference\", \"travel\"),\n",
        "    (\"car parking fee\", \"travel\"),\n",
        "    (\"bike rental for city tour\", \"travel\"),\n",
        "    (\"flight upgrade to premium economy\", \"travel\"),\n",
        "    (\"bus fare to work\", \"travel\"),\n",
        "    (\"long distance train ticket\", \"travel\"),\n",
        "    (\"auto rickshaw fare\", \"travel\"),\n",
        "    (\"ferry ride ticket\", \"travel\"),\n",
        "    (\"car wash before road trip\", \"travel\"),\n",
        "    (\"tourist sightseeing bus ticket\", \"travel\"),\n",
        "    (\"cab ride to airport early morning\", \"travel\"),\n",
        "    (\"overnight stay at roadside motel\", \"travel\"),\n",
        "    (\"petrol top-up at gas station\", \"travel\"),\n",
        "    (\"commuter bus monthly pass\", \"travel\"),\n",
        "    (\"day trip bus rental\", \"travel\"),\n",
        "    (\"airport lounge access fee\", \"travel\"),\n",
        "    (\"checked baggage upgrade fee\", \"travel\"),\n",
        "    (\"intercity taxi payment\", \"travel\"),\n",
        "    (\"flight ticket cancellation fee\", \"travel\"),\n",
        "    (\"hotel booking at beach resort\", \"travel\"),\n",
        "    (\"auto ride to market\", \"travel\"),\n",
        "    (\"weekly train commute pass\", \"travel\"),\n",
        "    (\"car rental for business meeting\", \"travel\"),\n",
        "    (\"taxi from workplace to home\", \"travel\"),\n",
        "    (\"reserved sleeper coach ticket\", \"travel\"),\n",
        "    (\"paid for shared cab ride\", \"travel\"),\n",
        "    (\"purchase of travel insurance\", \"travel\"),\n",
        "    (\"bike petrol refill\", \"travel\"),\n",
        "    (\"bridge toll tax\", \"travel\"),\n",
        "    (\"cruise boarding ticket\", \"travel\"),\n",
        "    (\"interstate bus ticket\", \"travel\"),\n",
        "    (\"flight seat selection add-on\", \"travel\"),\n",
        "    (\"uber ride during rain\", \"travel\"),\n",
        "    (\"taxi fare after midnight\", \"travel\"),\n",
        "    (\"booking bus to hill station\", \"travel\"),\n",
        "    (\"travel bag storage fee\", \"travel\"),\n",
        "    (\"boat ride on weekend trip\", \"travel\"),\n",
        "    (\"hotel late checkout fee\", \"travel\"),\n",
        "    (\"visa fee payment\", \"travel\"),\n",
        "    (\"parking ticket at mall\", \"travel\"),\n",
        "    (\"bus ride to college\", \"travel\"),\n",
        "    (\"train journey meal charge\", \"travel\"),\n",
        "    (\"metro one-day pass\", \"travel\"),\n",
        "    (\"uber share ride\", \"travel\"),\n",
        "    (\"taxi hired for entire day\", \"travel\"),\n",
        "    (\"flight drinks purchase\", \"travel\"),\n",
        "    (\"shuttle to hotel from airport\", \"travel\"),\n",
        "    (\"late night cab back home\", \"travel\"),\n",
        "    (\"electricity bill payment\", \"bills\"),\n",
        "    (\"internet broadband monthly bill\", \"bills\"),\n",
        "    (\"water bill payment\", \"bills\"),\n",
        "    (\"gas cylinder booking\", \"bills\"),\n",
        "    (\"mobile postpaid plan payment\", \"bills\"),\n",
        "    (\"spotify subscription renewal\", \"bills\"),\n",
        "    (\"netflix membership fee\", \"bills\"),\n",
        "    (\"amazon prime annual subscription\", \"bills\"),\n",
        "    (\"credit card bill settlement\", \"bills\"),\n",
        "    (\"insurance monthly premium\", \"bills\"),\n",
        "    (\"rent payment for apartment\", \"bills\"),\n",
        "    (\"cloud storage subscription\", \"bills\"),\n",
        "    (\"youtube premium renewal\", \"bills\"),\n",
        "    (\"phone recharge plan\", \"bills\"),\n",
        "    (\"gym membership monthly fee\", \"bills\"),\n",
        "    (\"newspaper subscription\", \"bills\"),\n",
        "    (\"water service maintenance fee\", \"bills\"),\n",
        "    (\"property tax payment\", \"bills\"),\n",
        "    (\"car loan EMI\", \"bills\"),\n",
        "    (\"bike EMI installment\", \"bills\"),\n",
        "    (\"electricity surcharge fee\", \"bills\"),\n",
        "    (\"annual health insurance payment\", \"bills\"),\n",
        "    (\"wifi router maintenance bill\", \"bills\"),\n",
        "    (\"monthly rent for co-working space\", \"bills\"),\n",
        "    (\"office software license renewal\", \"bills\"),\n",
        "    (\"vpn subscription fee\", \"bills\"),\n",
        "    (\"website domain renewal cost\", \"bills\"),\n",
        "    (\"server hosting charges\", \"bills\"),\n",
        "    (\"gas pipeline monthly fee\", \"bills\"),\n",
        "    (\"tv cable bill\", \"bills\"),\n",
        "    (\"home loan EMI\", \"bills\"),\n",
        "    (\"digital magazine subscription\", \"bills\"),\n",
        "    (\"kindle unlimited subscription\", \"bills\"),\n",
        "    (\"antivirus software plan\", \"bills\"),\n",
        "    (\"school fee installment\", \"bills\"),\n",
        "    (\"tuition payment\", \"bills\"),\n",
        "    (\"electricity reconnection charge\", \"bills\"),\n",
        "    (\"late payment fee for phone bill\", \"bills\"),\n",
        "    (\"cloud computing usage bill\", \"bills\"),\n",
        "    (\"landline phone bill\", \"bills\"),\n",
        "    (\"music app yearly plan\", \"bills\"),\n",
        "    (\"mobile insurance renewal\", \"bills\"),\n",
        "    (\"home maintenance charges\", \"bills\"),\n",
        "    (\"college exam fee\", \"bills\"),\n",
        "    (\"canteen monthly card top-up\", \"bills\"),\n",
        "    (\"apartment maintenance charges\", \"bills\"),\n",
        "    (\"gas usage bill\", \"bills\"),\n",
        "    (\"water tanker purchase\", \"bills\"),\n",
        "    (\"laundry subscription fee\", \"bills\"),\n",
        "    (\"online course subscription\", \"bills\"),\n",
        "    (\"software update license fee\", \"bills\"),\n",
        "    (\"streaming service add-on pack\", \"bills\"),\n",
        "    (\"health checkup fee\", \"bills\"),\n",
        "    (\"doctor consultation bill\", \"bills\"),\n",
        "    (\"medical insurance co-pay\", \"bills\"),\n",
        "    (\"mobile data add-on pack\", \"bills\"),\n",
        "    (\"app subscription renewal\", \"bills\"),\n",
        "    (\"electricity meter service fee\", \"bills\"),\n",
        "    (\"club membership renewal\", \"bills\"),\n",
        "    (\"internet late fee payment\", \"bills\"),\n",
        "    (\"wifi installation charge\", \"bills\"),\n",
        "    (\"school bus fee\", \"bills\"),\n",
        "    (\"storage locker rent\", \"bills\"),\n",
        "    (\"mortgage repayment\", \"bills\"),\n",
        "    (\"kindergarten monthly fee\", \"bills\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing and data utilities\n",
        "\n",
        "# tokenization and normalization\n",
        "def preprocess(text):\n",
        "  return [word.lower() for word in text.split(\" \") if word.isalpha()]\n",
        "\n",
        "# numericalization (building vocabulary and label maps)\n",
        "def build_maps(data):\n",
        "  # building the vocabulary map\n",
        "  vocab_map = {}\n",
        "  all_tokens = []\n",
        "\n",
        "  for text, _ in data:\n",
        "    tokens = preprocess(text)\n",
        "    all_tokens.extend(tokens)\n",
        "\n",
        "  unique_tokens = list(set(all_tokens))\n",
        "\n",
        "  for index, token in enumerate(unique_tokens, start = 1):\n",
        "    vocab_map[token] = index\n",
        "\n",
        "  vocab_map['<PAD>']  = 0\n",
        "\n",
        "  # building the label map\n",
        "  label_map = {}\n",
        "\n",
        "  unique_labels = sorted(list(set(label for _, label in data)))\n",
        "\n",
        "  for index, label in enumerate(unique_labels):\n",
        "    label_map[label] = index\n",
        "\n",
        "  return vocab_map, label_map\n",
        "\n",
        "class TransactionDataset(Dataset):\n",
        "  def __init__(self, data, vocab_map, label_map, max_len):\n",
        "    self.data = data\n",
        "    self.vocab_map = vocab_map\n",
        "    self.label_map = label_map\n",
        "    self.max_len = max_len\n",
        "    self.pad_idx = vocab_map['<PAD>']\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text, label = self.data[idx]\n",
        "    tokens = preprocess(text)\n",
        "\n",
        "    token_integers = [self.vocab_map.get(token, self.pad_idx) for token in tokens]\n",
        "\n",
        "    # padding and truncation\n",
        "    if len(token_integers) < self.max_len:\n",
        "        token_integers.extend([self.pad_idx] * (self.max_len - len(token_integers)))\n",
        "    elif len(token_integers) > self.max_len:\n",
        "        token_integers = token_integers[:self.max_len]\n",
        "\n",
        "    text_tensor = torch.tensor(token_integers, dtype=torch.long)\n",
        "    label_tensor = torch.tensor(self.label_map[label], dtype=torch.long)\n",
        "\n",
        "    return text_tensor, label_tensor"
      ],
      "metadata": {
        "id": "MIt9F9UvBIZQ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model architecture\n",
        "class TransactionClassifier(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(num_embeddings= vocab_size, embedding_dim = embedding_dim, padding_idx = 0)\n",
        "    self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size, num_layers = 1, bias = True)\n",
        "    self.linear = nn.Linear(in_features = hidden_size, out_features = num_classes)\n",
        "\n",
        "  def forward(self, text_input):\n",
        "    embedded = self.embedding(text_input)\n",
        "    _, (h_n, _) = self.lstm(embedded)\n",
        "    final_hidden_state = h_n[0]\n",
        "    logits = self.linear(final_hidden_state)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "WiAmgltLGyIH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation logic\n",
        "def evaluate(model, data_loader, criterion):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  correct_predictions = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in data_loader:\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "      total_samples += labels.size(0)\n",
        "\n",
        "  accuracy = (correct_predictions/total_samples)*100\n",
        "  average_loss = (total_loss/total_samples)\n",
        "\n",
        "  return average_loss , accuracy\n"
      ],
      "metadata": {
        "id": "oSLoJI32gL51"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execution\n",
        "vocab_map, label_map = build_maps(DATA)\n",
        "VOCAB_SIZE = len(vocab_map)\n",
        "NUM_CLASSES = len(label_map)\n",
        "\n",
        "# create and split the datasets (training and testing datasets)\n",
        "full_dataset = TransactionDataset(DATA, vocab_map, label_map, MAX_LENGTH)\n",
        "training_size = int((1 - TEST_SPLIT_RATIO) * len(full_dataset))\n",
        "testing_size = len(full_dataset) - training_size\n",
        "training_data, testing_data = random_split(full_dataset, [training_size, testing_size])\n",
        "\n",
        "training_loader = DataLoader(training_data, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
        "testing_loader = DataLoader(testing_data, batch_size = BATCH_SIZE, shuffle = False)\n",
        "\n",
        "# initialize model, optimizer and loss function\n",
        "model = TransactionClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "print(f\"Total Examples: {len(full_dataset)} | Train: {training_size} | Test: {testing_size} | Vocab Size: {VOCAB_SIZE}\")\n",
        "print(f\"Starting Training ({NUM_EPOCHS} epochs)\")\n",
        "start_time = time()\n",
        "\n",
        "# training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model.train()\n",
        "  for inputs, labels in training_loader:\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass (gradient descent, parameter updates)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss, train_accuracy = evaluate(model, training_loader, criterion)\n",
        "  test_loss, test_accuracy = evaluate(model, testing_loader, criterion)\n",
        "  print(f\"Epoch: {epoch} | Training loss: {train_loss} | Training accuracy: {train_accuracy} | Testing loss: {test_loss} | Testing accuracy: {test_accuracy}\")\n",
        "\n",
        "end_time = time()\n",
        "print(f\"Time taken to train model: {(end_time - start_time)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utK72yYxj9nh",
        "outputId": "4ce501eb-b140-450a-a20b-f9e05cc20319"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Examples: 173 | Train: 138 | Test: 35 | Vocab Size: 313\n",
            "Starting Training (20 epochs)\n",
            "Epoch: 0 | Training loss: 1.0864427340658087 | Training accuracy: 33.08270676691729 | Testing loss: 1.1142228364944458 | Testing accuracy: 22.857142857142858\n",
            "Epoch: 1 | Training loss: 1.0937497929522866 | Training accuracy: 36.09022556390977 | Testing loss: 1.1196852684020997 | Testing accuracy: 28.57142857142857\n",
            "Epoch: 2 | Training loss: 1.0874060831571881 | Training accuracy: 42.857142857142854 | Testing loss: 1.1231327056884766 | Testing accuracy: 28.57142857142857\n",
            "Epoch: 3 | Training loss: 1.0837098265949048 | Training accuracy: 37.59398496240601 | Testing loss: 1.1255239248275757 | Testing accuracy: 25.71428571428571\n",
            "Epoch: 4 | Training loss: 1.1012830922478123 | Training accuracy: 38.34586466165413 | Testing loss: 1.1297470808029175 | Testing accuracy: 28.57142857142857\n",
            "Epoch: 5 | Training loss: 1.0832093295298124 | Training accuracy: 43.609022556390975 | Testing loss: 1.1282519578933716 | Testing accuracy: 28.57142857142857\n",
            "Epoch: 6 | Training loss: 1.0894014333423816 | Training accuracy: 37.59398496240601 | Testing loss: 1.1291511535644532 | Testing accuracy: 34.285714285714285\n",
            "Epoch: 7 | Training loss: 1.0993206187298423 | Training accuracy: 38.34586466165413 | Testing loss: 1.1369672417640686 | Testing accuracy: 31.428571428571427\n",
            "Epoch: 8 | Training loss: 1.086367064400723 | Training accuracy: 40.6015037593985 | Testing loss: 1.1344318151474 | Testing accuracy: 25.71428571428571\n",
            "Epoch: 9 | Training loss: 1.081881206286581 | Training accuracy: 39.097744360902254 | Testing loss: 1.1302271485328674 | Testing accuracy: 31.428571428571427\n",
            "Epoch: 10 | Training loss: 1.086451884947325 | Training accuracy: 40.6015037593985 | Testing loss: 1.13316251039505 | Testing accuracy: 31.428571428571427\n",
            "Epoch: 11 | Training loss: 1.091391964962608 | Training accuracy: 40.6015037593985 | Testing loss: 1.1134932041168213 | Testing accuracy: 37.142857142857146\n",
            "Epoch: 12 | Training loss: 1.0666882458486056 | Training accuracy: 39.849624060150376 | Testing loss: 1.114005196094513 | Testing accuracy: 37.142857142857146\n",
            "Epoch: 13 | Training loss: 1.0573211563260931 | Training accuracy: 44.3609022556391 | Testing loss: 1.106082010269165 | Testing accuracy: 40.0\n",
            "Epoch: 14 | Training loss: 1.0819074291931956 | Training accuracy: 42.10526315789473 | Testing loss: 1.1110678315162659 | Testing accuracy: 37.142857142857146\n",
            "Epoch: 15 | Training loss: 1.0925873361135785 | Training accuracy: 39.849624060150376 | Testing loss: 1.097135639190674 | Testing accuracy: 42.857142857142854\n",
            "Epoch: 16 | Training loss: 1.0878448674553318 | Training accuracy: 38.34586466165413 | Testing loss: 1.1100253939628602 | Testing accuracy: 34.285714285714285\n",
            "Epoch: 17 | Training loss: 1.0942729993870384 | Training accuracy: 36.84210526315789 | Testing loss: 1.120683217048645 | Testing accuracy: 37.142857142857146\n",
            "Epoch: 18 | Training loss: 1.0851953406082957 | Training accuracy: 40.6015037593985 | Testing loss: 1.1296531081199646 | Testing accuracy: 37.142857142857146\n",
            "Epoch: 19 | Training loss: 1.0587971147738005 | Training accuracy: 47.368421052631575 | Testing loss: 1.1244632720947265 | Testing accuracy: 37.142857142857146\n",
            "Time taken to train model: 2.229933500289917 seconds\n"
          ]
        }
      ]
    }
  ]
}